(window.webpackJsonp=window.webpackJsonp||[]).push([[8],{122:function(e,t,a){"use strict";a.d(t,"a",(function(){return b})),a.d(t,"b",(function(){return d}));var r=a(0),n=a.n(r);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function l(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,r)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?l(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function c(e,t){if(null==e)return{};var a,r,n=function(e,t){if(null==e)return{};var a,r,n={},i=Object.keys(e);for(r=0;r<i.length;r++)a=i[r],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)a=i[r],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var u=n.a.createContext({}),s=function(e){var t=n.a.useContext(u),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},b=function(e){var t=s(e.components);return n.a.createElement(u.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return n.a.createElement(n.a.Fragment,{},t)}},m=n.a.forwardRef((function(e,t){var a=e.components,r=e.mdxType,i=e.originalType,l=e.parentName,u=c(e,["components","mdxType","originalType","parentName"]),b=s(a),m=r,d=b["".concat(l,".").concat(m)]||b[m]||p[m]||i;return a?n.a.createElement(d,o(o({ref:t},u),{},{components:a})):n.a.createElement(d,o({ref:t},u))}));function d(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=a.length,l=new Array(i);l[0]=m;var o={};for(var c in t)hasOwnProperty.call(t,c)&&(o[c]=t[c]);o.originalType=e,o.mdxType="string"==typeof e?e:r,l[1]=o;for(var u=2;u<i;u++)l[u]=a[u];return n.a.createElement.apply(null,l)}return n.a.createElement.apply(null,a)}m.displayName="MDXCreateElement"},70:function(e,t,a){"use strict";a.r(t),a.d(t,"frontMatter",(function(){return l})),a.d(t,"metadata",(function(){return o})),a.d(t,"rightToc",(function(){return c})),a.d(t,"default",(function(){return s}));var r=a(3),n=a(7),i=(a(0),a(122)),l={id:"features",title:"Features"},o={unversionedId:"features",id:"features",isDocsHomePage:!1,title:"Features",description:"Smart Data Lake Builder is still under heavy development so new features are added all the time.",source:"@site/docs/features.md",slug:"/features",permalink:"/sdl-docs/docs/features",version:"current",sidebar:"docs",previous:{title:"Introduction",permalink:"/sdl-docs/docs/"},next:{title:"Technical Setup",permalink:"/sdl-docs/docs/getting-started/setup"}},c=[{value:"Filebased metadata",id:"filebased-metadata",children:[]},{value:"Support for complex workflows &amp; streaming",id:"support-for-complex-workflows--streaming",children:[]},{value:"Execution Engines",id:"execution-engines",children:[]},{value:"Connectivity",id:"connectivity",children:[]},{value:"Generic Transformations",id:"generic-transformations",children:[]},{value:"Customizable Transformations",id:"customizable-transformations",children:[]},{value:"Early Validation",id:"early-validation",children:[]},{value:"Execution Modes",id:"execution-modes",children:[]},{value:"Schema Evolution",id:"schema-evolution",children:[]},{value:"Metrics",id:"metrics",children:[]},{value:"Data Catalog",id:"data-catalog",children:[]},{value:"Lineage",id:"lineage",children:[]},{value:"Data Quality",id:"data-quality",children:[]},{value:"Testing",id:"testing",children:[]},{value:"Spark Performance",id:"spark-performance",children:[]},{value:"Housekeeping",id:"housekeeping",children:[]}],u={rightToc:c};function s(e){var t=e.components,a=Object(n.a)(e,["components"]);return Object(i.b)("wrapper",Object(r.a)({},u,a,{components:t,mdxType:"MDXLayout"}),Object(i.b)("p",null,"Smart Data Lake Builder is still under heavy development so new features are added all the time.\nThe following list will give you a rough overview of current and planned features.\nMore details on the roadmap will follow shortly."),Object(i.b)("h2",{id:"filebased-metadata"},"Filebased metadata"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Easy to version with a VCS for DevOps"),Object(i.b)("li",{parentName:"ul"},"Flexible structure by splitting over multiple files and subdirectories"),Object(i.b)("li",{parentName:"ul"},"Easy to generate from third party metadata (e.g. source system table catalog) to automate transformation of large number of DataObjects")),Object(i.b)("h2",{id:"support-for-complex-workflows--streaming"},"Support for complex workflows & streaming"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Fork, join, parallel execution, multiple start- & end-nodes possible"),Object(i.b)("li",{parentName:"ul"},"Recovery of failed runs"),Object(i.b)("li",{parentName:"ul"},"Switch a workflow between batch or streaming execution by using just a command line switch")),Object(i.b)("h2",{id:"execution-engines"},"Execution Engines"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Spark (DataFrames)"),Object(i.b)("li",{parentName:"ul"},"File (Input&OutputStream)"),Object(i.b)("li",{parentName:"ul"},"Future: Kafka Streams, Flink, \u2026")),Object(i.b)("h2",{id:"connectivity"},"Connectivity"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Spark: diverse connectors (HadoopFS, Hive, DeltaLake, JDBC, Kafka, Splunk, Webservice, JMS) and formats (CSV, JSON, XML, Avro, Parquet, Excel, Access \u2026)"),Object(i.b)("li",{parentName:"ul"},"File: SFTP, Local, Webservice"),Object(i.b)("li",{parentName:"ul"},"Easy to extend by implementing predefined scala traits"),Object(i.b)("li",{parentName:"ul"},"Support for getting secrets from different secret providers"),Object(i.b)("li",{parentName:"ul"},"Support for SQL update & merge (Jdbc, DeltaLake)")),Object(i.b)("h2",{id:"generic-transformations"},"Generic Transformations"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Spark based: Copy, Historization, Deduplication (incl. incremental update/merge mode for streaming)"),Object(i.b)("li",{parentName:"ul"},"File based: FileTransfer"),Object(i.b)("li",{parentName:"ul"},"Easy to extend by implementing predefined scala traits"),Object(i.b)("li",{parentName:"ul"},"Future: applying MLFlow machine learning models")),Object(i.b)("h2",{id:"customizable-transformations"},"Customizable Transformations"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Spark Transformations:",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Chain predefined standard transformations (e.g. filter, row level data validation and more) and custom transformations within the same action"),Object(i.b)("li",{parentName:"ul"},"Custom Transformation Languages: SQL, Scala (Class, compile from config), Python"),Object(i.b)("li",{parentName:"ul"},"Many input DataFrames to many outputs DataFrames (but only one output recommended normally, in order to define dependencies as detailed as possible for the lineage)"),Object(i.b)("li",{parentName:"ul"},"Add metadata to each transformation to explain your data pipeline."))),Object(i.b)("li",{parentName:"ul"},"File Transformations:",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Language: Scala"),Object(i.b)("li",{parentName:"ul"},"Only one to one (one InputStream to one OutputStream)")))),Object(i.b)("h2",{id:"early-validation"},"Early Validation"),Object(i.b)("p",null,"(see ",Object(i.b)("a",Object(r.a)({parentName:"p"},{href:"/sdl-docs/docs/reference/executionPhases"}),"execution phases")," for details)"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Execution in 3 phases before execution",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Load Config: validate configuration"),Object(i.b)("li",{parentName:"ul"},"Prepare: validate connections"),Object(i.b)("li",{parentName:"ul"},"Init: validate Spark DataFrame Lineage (missing columns in transformations of later actions will stop the execution)")))),Object(i.b)("h2",{id:"execution-modes"},"Execution Modes"),Object(i.b)("p",null,"(see ",Object(i.b)("a",Object(r.a)({parentName:"p"},{href:"/sdl-docs/docs/reference/executionModes"}),"execution Modes")," for details)"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Process all data"),Object(i.b)("li",{parentName:"ul"},"Partition parameters: give partition values to process for start nodes as parameter"),Object(i.b)("li",{parentName:"ul"},"Partition Diff: search missing partitions and use as parameter"),Object(i.b)("li",{parentName:"ul"},"Spark Incremental: compare sortable column between source and target, load the difference"),Object(i.b)("li",{parentName:"ul"},"Spark Streaming: asynchronous incremental processing by using Spark Structured Streaming"),Object(i.b)("li",{parentName:"ul"},"Spark Streaming Once: synchronous incremental processing by using Spark Structured Streaming with Trigger=Once mode")),Object(i.b)("h2",{id:"schema-evolution"},"Schema Evolution"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Automatic evolution of data schemas (new column, removed column, changed datatype)"),Object(i.b)("li",{parentName:"ul"},"Support for changes in complex datatypes (e.g. new column in array of struct)"),Object(i.b)("li",{parentName:"ul"},"Automatic adaption of DataObjects with fixed schema (Jdbc, DeltaLake)")),Object(i.b)("h2",{id:"metrics"},"Metrics"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Number of rows written per DataObject"),Object(i.b)("li",{parentName:"ul"},"Execution duration per Action"),Object(i.b)("li",{parentName:"ul"},"StateListener interface to get notified about progress & metrics")),Object(i.b)("h2",{id:"data-catalog"},"Data Catalog"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Report all DataObjects attributes (incl. foreign keys if defined) for visualisation of data catalog in BI tool"),Object(i.b)("li",{parentName:"ul"},"Metadata support for categorizing Actions and DataObjects"),Object(i.b)("li",{parentName:"ul"},"Custom metadata attributes")),Object(i.b)("h2",{id:"lineage"},"Lineage"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Report all dependencies between DataObjects for visualisation of lineage in BI tool")),Object(i.b)("h2",{id:"data-quality"},"Data Quality"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Metadata support for primary & foreign keys"),Object(i.b)("li",{parentName:"ul"},"Check & report primary key violations by executing primary key checker action"),Object(i.b)("li",{parentName:"ul"},"Future: Metadata support for arbitrary data quality checks"),Object(i.b)("li",{parentName:"ul"},"Future: Report data quality (foreign key matching & arbitrary data quality checks) by executing data quality reporter action")),Object(i.b)("h2",{id:"testing"},"Testing"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Support for CI",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Config validation"),Object(i.b)("li",{parentName:"ul"},"Custom transformation unit tests"),Object(i.b)("li",{parentName:"ul"},"Spark data pipeline simulation (acceptance tests)"))),Object(i.b)("li",{parentName:"ul"},"Support for Deployment",Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},"Dry-run")))),Object(i.b)("h2",{id:"spark-performance"},"Spark Performance"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Execute multiple Spark jobs in parallel within the same Spark Session to save resources"),Object(i.b)("li",{parentName:"ul"},"Automatically cache and release intermediate results (DataFrames)")),Object(i.b)("h2",{id:"housekeeping"},"Housekeeping"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Delete, or archive & compact partitions according to configurable expressions")))}s.isMDXComponent=!0}}]);